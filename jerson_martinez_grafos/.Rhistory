epsilon <- 1e-6
entropy <- -sum((degs + epsilon) * log(degs + epsilon))
print(paste("Entropía de los nodos:", entropy))
table(degs)
table(degs, 1)
table(degs)/2
# Entropía de los nodos
# Calcular la distribución de grado de los nodos
degree_distribution <- degree_distribution(g)
table(degree_distribution)
# Entropía de los nodos
# Calcular la distribución de grado de los nodos
degree_distribution <- degree_distribution(g2)
# Entropía de los nodos
# Calcular la distribución de grado de los nodos
degree_distribution <- degree_distribution(g2)
table(degree_distribution)
?
g2
table(degree(g2))
# Obtener la distribución de grados del grafo
degree_distribution <- table(degree(g2))
# Calcular la proporción de nodos para cada grado
degree_distribution <- degree_distribution / sum(degree_distribution)
degree_distribution
# Calcular la entropía
entropy <- -sum(degree_distribution * log(degree_distribution))
# Imprimir la entropía
print(paste("Entropía de los nodos:", entropy))
# Obtener la distribución de grados del grafo
degree_distribution <- degree_distribution(g2, cumulative = FALSE)
degree_distribution
# Centralidad de los nodos y comparación con métricas de grado y clustering
centrality <- centr_degree(g2)$centrality
print(paste("Centralidad de los nodos:", centrality))
centrality
# Centralidad de los nodos y comparación con métricas de grado y clustering
centrality <- centr_degree(g2)$centralization
centrality
print(paste("Centralidad de los nodos:", centrality))
# Algoritmo de Louvain
louvain_clusters <- cluster_louvain(g2)
# Algoritmo Girvan-Newman
girvan_newman_clusters <- cluster_edge_betweenness(g2)
### Inserta aqui tu codigo
# Algoritmo de Louvain
louvain_clusters <- cluster_louvain(g2)
# Algoritmo Girvan-Newman
girvan_newman_clusters <- cluster_edge_betweenness(g2)
# Algoritmo de Louvain
louvain_clusters <- cluster_louvain(g2)
# Calcular la modularidad de ambos métodos
modularity_louvain <- modularity(louvain_clusters)
# Imprimir la modularidad
print(paste("Modularidad del algoritmo de Louvain:", modularity_louvain))
# Visualizar los resultados (opcional)
plot(louvain_clusters, g2, main = "Comunidades detectadas por Louvain")
### Inserta aqui tu codigo
cols <- rainbow(vcount(g2))
ll <- layout.fruchterman.reingold(g2)
png("tt.png", width = 1000, height = 1000, res = 100)
plot(g2, vertex.label= "", vertex.color = cols, layout=ll, vertex.size = (log(degree(g2))+1))
dev.off()
### Inserta aqui tu codigo
cols <- rainbow(vcount(louvain_clusters))
# Aplicar algoritmo de detección de comunidades (usando Louvain como ejemplo)
# Supongamos que communities contiene las comunidades detectadas
# Asignar colores a cada comunidad
cols <- rainbow(length(louvain_clusters))
# Crear un vector de colores para los nodos basado en las comunidades
node_colors <- rep(NA, vcount(g2))
for (i in 1:length(louvain_clusters)) {
node_colors[louvain_clusters[[i]]] <- cols[i]
}
# Definir el layout con un algoritmo de posicionamiento
# Puedes probar diferentes algoritmos, como "layout_with_fr", "layout_with_kk", etc.
# Aquí usaremos "layout_with_fr" como ejemplo
layout <- layout_with_fr(g2)
# Ajustar el tamaño de la ventana de visualización según el tamaño del grafo
width <- 1000
height <- 1000
# Guardar la visualización en un archivo PNG
png("graph_communities.png", width = width, height = height, res = 100)
plot(
g2,
vertex.label = NA,
vertex.size = 5,  # Ajustar el tamaño de los nodos según sea necesario
vertex.color = node_colors,
edge.color = "gray",
layout = layout
)
dev.off()
library(ggplot2)
library(gridExtra)
simulate_SIR <- function(N, beta, gamma, graph) {
# Inicializar el estado de los nodos: 0 para Susceptible, 1 para Infectado, 2 para Recuperado
node_states <- rep(0, vcount(graph))
# Seleccionar N nodos al azar para iniciar como infectados
initial_infected <- sample(1:vcount(graph), N)
node_states[initial_infected] <- 1
# Inicializar el número de nuevos infectados en cada iteración
new_infected <- vector()
# Iterar hasta que no haya nuevos infectados durante 3 iteraciones consecutivas
consecutive_no_new_infected <- 0
while (consecutive_no_new_infected < 3) {
# Inicializar el número de nuevos infectados en esta iteración
current_new_infected <- 0
# Iterar sobre los nodos para actualizar su estado
for (node in 1:vcount(graph)) {
# Si el nodo es Susceptible
if (node_states[node] == 0) {
# Verificar si tiene vecinos infectados y contagiar con probabilidad beta
neighbors <- neighbors(graph, node)
if (length(neighbors) > 0 && any(node_states[neighbors] == 1)) {
if (runif(1) < beta) {
node_states[node] <- 1  # Infectar el nodo
current_new_infected <- current_new_infected + 1
}
}
}
# Si el nodo es Infectado, verificar si se recupera con probabilidad gamma
else if (node_states[node] == 1) {
if (runif(1) < gamma) {
node_states[node] <- 2  # Marcar el nodo como Recuperado
}
}
}
# Registrar el número de nuevos infectados en esta iteración
new_infected <- c(new_infected, current_new_infected)
# Verificar si hubo nuevos infectados en esta iteración
if (current_new_infected == 0) {
consecutive_no_new_infected <- consecutive_no_new_infected + 1
} else {
consecutive_no_new_infected <- 0
}
}
# Devolver el número de nuevos infectados en cada iteración
return(new_infected)
}
# Parámetros de la simulación
N <- 5
beta_values <- c(0.1, 0.3, 0.5)
gamma <- 0.1
# Crear el grafo
# Reemplaza esta parte con la creación de tu grafo específico
graph <- erdos.renyi.game(100, p = 0.05)
# List to store plots
plots <- list()
# Simular para cada valor de beta
for (beta in beta_values) {
# Simular el proceso SIR
new_infected <- simulate_SIR(N, beta, gamma, g2)
# Graficar el número de nuevos infectados en escala logarítmica
plot <- ggplot(data = data.frame(iteration = 1:length(new_infected), new_infected = new_infected)) +
geom_line(aes(x = iteration, y = log(new_infected)), color = "blue") +
labs(title = paste("Beta =", beta), x = "Iteration", y = "Log(Newly Infected)") +
theme_minimal()
plots[[length(plots) + 1]] <- plot
}
# Save GIF
gif <- paste0("SIR_simulation.gif")
gif <- animate(
plotlist = plots,
width = 600,
height = 400,
nframes = 50,
duration = 1,
start = 0,
end = 1,
rewind = FALSE
)
# Cargar la biblioteca animation
library(animation)
gif <- paste0("SIR_simulation.gif")
gif <- animate(
plotlist = plots,
width = 600,
height = 400,
nframes = 50,
duration = 1,
start = 0,
end = 1,
rewind = FALSE
)
# Cargar la biblioteca animation
install.packages('animation')
library(animation)
# Save GIF
gif <- paste0("SIR_simulation.gif")
gif <- animate(
plotlist = plots,
width = 600,
height = 400,
nframes = 50,
duration = 1,
start = 0,
end = 1,
rewind = FALSE
)
# Cargar la biblioteca animation
# Instalar y cargar la biblioteca devtools si aún no está instalada
if (!require(devtools)) {
install.packages("devtools")
library(devtools)
}
# Instalar la última versión de la biblioteca animation desde GitHub
devtools::install_github("yihui/animation")
library(animation)
gif <- paste0("SIR_simulation.gif")
gif <- animate(
plotlist = plots,
width = 600,
height = 400,
nframes = 50,
duration = 1,
start = 0,
end = 1,
rewind = FALSE
)
if (!require(magick)) {
install.packages("magick")
library(magick)
}
# Guardar cada trama como un archivo PNG
for (i in seq_along(plots)) {
filename <- paste0("plot", i, ".png")
magick::image_write(plots[[i]], path = filename)
}
library(magick)
for (i in seq_along(plots)) {
filename <- paste0("plot", i, ".png")
image_write(plots[[i]], path = filename)
}
library('animation')
# Lista para almacenar simulaciones
sims <- list()
View(g2)
summary(g2)
g2 <- as_igraph(g2)
g2 <- as.igraph(g2, directed = FALSE)
install.packages("igraph")
install.packages("igraph")
install.packages("igraph")
g2 <- as_igraph(g2)
library('igraph')
g2 <- as_igraph(g2)
### Inserta aqui tu codigo
# Carga del fichero
library(data.table)
data_red <- fread("red_contactos.csv", sep =  ";", col.names =c("origen", "destino"))
# Carga como grafo
library(igraph)
# graph
g_base <- graph_from_data_frame(data_red, directed = FALSE)
#install.packages('glue')
library(glue)
print(glue("Tenemos {vcount(g_base)} nodos y {gsize(g_base)} enlaces en nuestro grafo base."))
# Creo una columna 'weight' con valor 1 por enlace.
E(g_base)$weight <- 1
# Agrupo los enlaces por su peso 'weight' y elimino los enlaces propios.
g <- simplify(g_base, edge.attr.comb = "sum", remove.loops=TRUE)
# Verifico el resultado
print(glue("Pasamos a tener {gsize(g)} enlaces despúes de realizar un simplify en nuestro grafo base."))
# Pesos de los enlaces en el grafo consolidado
link_weights <- edge_attr(g, "weight")
# Estadisticos basicos de los enlaces entre nodos.
summary(link_weights)
### Inserta aqui tu codigo
# Carga del fichero
library(data.table)
data_red <- fread("red_contactos.csv", sep =  ";", col.names =c("origen", "destino"))
# Carga como grafo
library(igraph)
# graph
g_base <- graph_from_data_frame(data_red, directed = FALSE)
#install.packages('glue')
library(glue)
print(glue("Tenemos {vcount(g_base)} nodos y {gsize(g_base)} enlaces en nuestro grafo base."))
# Creo una columna 'weight' con valor 1 por enlace.
E(g_base)$weight <- 1
# Agrupo los enlaces por su peso 'weight' y elimino los enlaces propios.
g <- simplify(g_base, edge.attr.comb = "sum", remove.loops=TRUE)
# Verifico el resultado
print(glue("Pasamos a tener {gsize(g)} enlaces despúes de realizar un simplify en nuestro grafo base."))
# Pesos de los enlaces en el grafo consolidado
link_weights <- edge_attr(g, "weight")
# Estadisticos basicos de los enlaces entre nodos.
summary(link_weights)
### Inserta aqui tu codigo
# Identificar la componente conexa mayor del grafo original
cc <- clusters(g)
# Tenemos 3 clusters, casi todos los nodos estan continidos en el primer cluster
head(cc$csize)
# Identifico el grupo con mayor numeor de nodos.
cc_max <- which.max(cc$csize)
# Nodos de la componente conexa mayor
cc_conexa <- which(cc$membership == cc_max)
# Links de la componente conexa mayor
g2 <- induced_subgraph(g, cc_conexa)
print(glue("Número de nodos de la componente conexa mayor {vcount(g2)}. \nConectadas: {is_connected(g2)}"))
### Inserta aqui tu codigo
# Identificar la componente conexa mayor del grafo original
cc <- components(g)
# Tenemos 3 clusters, casi todos los nodos estan continidos en el primer cluster
head(cc$csize)
# Identifico el grupo con mayor numeor de nodos.
cc_max <- which.max(cc$csize)
# Nodos de la componente conexa mayor
cc_conexa <- which(cc$membership == cc_max)
# Links de la componente conexa mayor
g2 <- induced_subgraph(g, cc_conexa)
print(glue("Número de nodos de la componente conexa mayor {vcount(g2)}. \nConectadas: {is_connected(g2)}"))
### Inserta aqui tu codigo
# Grado medio
mean_degree <- mean(degree(g2))
nodos <- vcount(g2)
prop_conex <- (mean_degree/nodos)*100
print(glue("En promedio, cada nodo en el grafo tiene aproximadamente {round(mean_degree)} conexiones con otros nodos."))
print(glue("En promedio, cada nodo está conectado al {round(prop_conex, 3)} % de todos los nodos en la red."))
# Distancia media
mean_distance <- mean_distance(g2)
print(glue("Distancia media entre los nodos es de {round(mean_distance,2)}. Esto implica que, en general, los nodos están bastante cerca entre sí y que la red es relativamente compacta."))
# Diámetro
diameter <- diameter(g2)
print(glue("La distancia más larga entre dos nodos en tu grafo es de {diameter}. Lo cual indica que no hay ningún nodo más lejos de eso."))
# Distribución de grados y ajuste a una Power-Law
degs <- degree(g2)
# Cómo podemos observar de los 1388 nodos del grafo los 120 primeros tienen el 80% de las conexiones del grafo.
hist(degs, breaks = 30, main = "Distribución de grados", xlab = "Grado", ylab = "Frecuencia")
# Esto reafirma lo anterior, los grados altos se concentran entorno a los 120 nodos.
plot(density(degs), log ="xy")
# Clustering
clustering_coef <- mean(transitivity(g2))
print(glue(" La proporción de conexiones entre los vecinos de un nodo en relación con todas las posibles conexiones entre esos vecinos es de {round((clustering_coef*100),2)}%. Lo cual indica que se trata de un red cohesionada."))
# Entropía de los nodos
# Distribución de grados del grafo
degree_distribution <- table(degree(g2))
# Proporción de nodos para cada grado
degree_distribution <- degree_distribution / sum(degree_distribution)
# Entropía
entropy <- sum(degree_distribution * log(degree_distribution))
# print la entropía
print(glue("La entropía de los nodos es de {round(entropy,3)}. Lo cual sugiere que la distribución de grados está bastante concentrada, cómo veniamos comentando anteriormente."))
# Centralidad de los nodos y comparación con métricas de grado y clustering
centrality <- centr_degree(g2)$centralization
print(glue("La centralidad de los nodos es de {round((centrality*100),3)}%, lo cual indica que un 1/4 de los nodos en el grafo tienen un número significativamente mayor de conexiones en comparación con el resto de los nodos."))
### Inserta aqui tu codigo
# Algoritmo de Louvain
## algoritmo de particionamiento de grafos que busca maximizar la modularidad de la red al agrupar los nodos en comunidades densamente conectadas.
# La resolución determina el nivel de escala al que se forman las comunidades.
louvain_clusters <- cluster_louvain(g2,  weights = NULL, resolution = 0.3)
# Calcular la modularidad de ambos métodos
modularity_louvain <- modularity(louvain_clusters)
# print modularidad
print(glue("La modularidad del algoritmo de Louvain es de {round(modularity_louvain,3)}"))
# Configurar el tamaño y color de los nodos
color_nodos <- rainbow(max(membership(louvain_clusters)))
# Configurar la disposición del grafo
# Algoritmo de Fruchterman-Reingold
## algoritmo de disposición de fuerza que trata de encontrar una disposición de los nodos del grafo que minimice las repulsiones entre ellos mientras maximiza las atracciones de las aristas,
layout <- layout_with_fr(g2)
# Visualización de los grupos con louvain
plot(
louvain_clusters, g2,
layout = layout,
vertex.size = 5,
vertex.color = color_nodos,
vertex.label = NA,  # Desactivar etiquetas de nodos
edge.color = "gray",
main = "Comunidades detectadas por Louvain"
)
### Inserta aqui tu codigo
ll <- layout.fruchterman.reingold(g2)
plot(g2, vertex.label= NA,
vertex.color = color_nodos,
layout=ll,
edge.width = 1,
edge.color = "gray",
vertex.size = (log(degree(g2))+1))
simular_SIR <- function(N, beta, gamma, graph) {
# Inicialización del estado de los nodos a 0 (Susceptible)
node_states <- rep(0, vcount(graph))
# N nodos iniciales elegidos al azar como infectados
initial_infected <- sample(1:vcount(graph), N)
node_states[initial_infected] <- 1
# Vector de infectados en cada iteración
new_infected <- vector()
# Lista para guardar el grafo de contagios en cada iteración
contagion_graphs <- list()
# Grafo de contagios actual
contagion_graph <- make_empty_graph(vcount(graph), directed=TRUE)
# Iterar hasta que el número de nuevos infectados sea menor que 3
iter <- 1
while (TRUE) {
# Número de nuevos infectados en esta iteración
current_new_infected <- 0
# Iteración sobre los nodos para actualizar su estado
for (node in 1:vcount(graph)) {
# Si el nodo es Susceptible
if (node_states[node] == 0) {
# Verificar si tiene vecinos infectados que pueda contagiarlo con probabilidad beta
neighbors <- neighbors(graph, node)
if (length(neighbors) > 0 && any(node_states[neighbors] == 1)) {
for (neighbor in neighbors) {
if (node_states[neighbor] == 1 && runif(1) < beta) {
# Infecta al nodo
node_states[node] <- 1
current_new_infected <- current_new_infected + 1
# Añadir arista al grafo de contagios
contagion_graph <- add_edges(contagion_graph, c(neighbor, node))
break  # Salir del bucle una vez infectado
}
}
}
}
# Si el nodo está ya infectado, verificar si se recupera con probabilidad gamma
else if (node_states[node] == 1) {
if (runif(1) < gamma) {
# Marcar el nodo como Recuperado
node_states[node] <- 2
}
}
}
# Registro del número de nuevos infectados en esta iteración
new_infected <- c(new_infected, current_new_infected)
# Guardar el grafo de contagios en esta iteración
contagion_graphs[[iter]] <- list(
contagion_graph = contagion_graph,
node_states = node_states
)
# Verificar si el número de nuevos infectados en esta iteración es menor que 3
if (current_new_infected < 3) {
break
}
iter <- iter + 1
}
# Número de nuevos infectados en cada iteración y la lista de grafos de contagios
list(
new_infected = new_infected,
contagion_graphs = contagion_graphs,
initial_infected = initial_infected
)
}
# Parámetros de la simulación
N <- 1
betas <- c(0.3, 0.5, 0.7)
gamma <- 0.1
# Almacenar los resultados
results <- lapply(betas, function(beta) {
simular_SIR_gif(N, beta, gamma, g2)
})
# Almacenar los resultados
results <- lapply(betas, function(beta) {
simular_SIR(N, beta, gamma, g2)
})
# Curva de nuevos infectados en escala logarítmica
par(mfrow=c(1,1))
for (i in 1:length(betas)) {
new_infected <- results[[i]]$new_infected
plot(log1p(new_infected), type="o", main=paste("Beta =", betas[i]),
xlab="Iteración", ylab="Nuevos Infectados (log escala)")
}
simular_SIR <- function(N, beta, gamma, graph) {
# Inicialización del estado de los nodos a 0 (Susceptible)
node_states <- rep(0, vcount(graph))
# N nodos iniciales elegidos al azar como infectados
initial_infected <- sample(1:vcount(graph), N)
node_states[initial_infected] <- 1
# Vector de infectados en cada iteración
new_infected <- vector()
# listas
contagion_graphs <- list()
# Grafo de contagios actual
contagion_graph <- make_empty_graph(vcount(graph), directed=TRUE)
# Iterar hasta que el número de nuevos infectados sea menor que 3
iter <- 1
while (TRUE) {
# Número de nuevos infectados en esta iteración
current_new_infected <- 0
# Iteración sobre los nodos para actualizar su estado
for (node in 1:vcount(graph)) {
# Si el nodo es Susceptible
if (node_states[node] == 0) {
# Verificar si tiene vecinos infectados que pueda contagiarlo con probabilidad beta
neighbors <- neighbors(graph, node)
if (length(neighbors) > 0 && any(node_states[neighbors] == 1)) {
for (neighbor in neighbors) {
if (node_states[neighbor] == 1 && runif(1) < beta) {
# Infecta al nodo
node_states[node] <- 1
current_new_infected <- current_new_infected + 1
# Añadir arista al grafo de contagios
contagion_graph <- add_edges(contagion_graph, c(neighbor, node))
break  # Salir del bucle una vez infectado
}
}
}
}
# Si el nodo está ya infectado, verificar si se recupera con probabilidad gamma
else if (node_states[node] == 1) {
if (runif(1) < gamma) {
# Marcar el nodo como Recuperado
node_states[node] <- 2
}
}
}
# Registro del número de nuevos infectados en esta iteración
new_infected <- c(new_infected, current_new_infected)
stop
# Guardar el grafo de contagios en esta iteración
contagion_graphs[[iter]] <- list(
contagion_graph = contagion_graph,
